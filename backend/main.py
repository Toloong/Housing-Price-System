from fastapi import FastAPI, HTTPException, Depends, status
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import pandas as pd
import numpy as np
from dateutil.relativedelta import relativedelta
import datetime
import os
import json
from typing import Optional
from fastapi import APIRouter, HTTPException, Depends
from pydantic import BaseModel
from typing import List, Optional
import pandas as pd
import numpy as np
import os
import joblib
from datetime import datetime, timedelta
# å¯¼å…¥æ•°æ®åº“æ¨¡å—ï¼ˆä½¿ç”¨SQLiteï¼‰
from backend.database import init_sqlite_database, SQLiteUserManager, log_sqlite_user_activity
UserManager = SQLiteUserManager
log_user_activity = log_sqlite_user_activity
DB_TYPE = "sqlite"

import os
import json
import requests
from typing import Dict, Any, Optional
import pandas as pd

class AIService:
    def __init__(self, api_key: str = None):
        self.api_key = api_key or "MDc3YWI0YjUtMDdlYi00Y2Y3LTgzMTAtZTA4OGQ5NTBkOGFh"
        self.api_url = "https://chat3.eqing.tech/v1/chat/completions"

        if not self.api_key:
            raise ValueError("AI APIå¯†é’¥æœªè®¾ç½®")

    def chat_with_ai(self, prompt: str, system_prompt: str = None, temperature: float = 0.3) -> Dict[str, Any]:
        """
        è°ƒç”¨AI APIè¿›è¡Œå¯¹è¯ - ä¿®å¤ç‰ˆæœ¬
        """
        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.api_key}"
            }

            messages = []

            # æ·»åŠ ç³»ç»Ÿæç¤º
            if system_prompt:
                messages.append({
                    "role": "system",
                    "content": system_prompt
                })

            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            messages.append({
                "role": "user",
                "content": prompt
            })

            payload = {
                "model": "gpt-3.5-turbo",
                "messages": messages,
                "temperature": temperature,
                "max_tokens": 1500,  # å‡å°‘tokenæ•°é‡é¿å…è¶…é™
                "stream": False
            }

            print(f"ğŸ”„ å‘é€AIè¯·æ±‚...")
            print(f"ğŸ“ Prompté•¿åº¦: {len(prompt)} å­—ç¬¦")

            response = requests.post(
                self.api_url,
                headers=headers,
                json=payload,
                timeout=30
            )

            print(f"ğŸ“Š APIå“åº”çŠ¶æ€: {response.status_code}")

            if response.status_code != 200:
                print(f"âŒ APIé”™è¯¯å“åº”: {response.text}")
                return {"error": f"APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}"}

            result = response.json()
            print(f"âœ… APIè°ƒç”¨æˆåŠŸ")

            # æå–AIå›å¤å†…å®¹
            if "choices" in result and len(result["choices"]) > 0:
                content = result["choices"][0]["message"]["content"]

                # ç›´æ¥è¿”å›æ–‡æœ¬å†…å®¹ï¼Œä¸è¦å°è¯•è§£æJSON
                return {
                    "text": content,
                    "raw_response": True,
                    "model_used": result.get("model", "gpt-3.5-turbo"),
                    "tokens_used": result.get("usage", {}).get("total_tokens", 0)
                }
            else:
                print(f"âŒ APIè¿”å›æ ¼å¼å¼‚å¸¸: {result}")
                return {"error": "APIè¿”å›æ ¼å¼å¼‚å¸¸"}

        except requests.exceptions.Timeout:
            print("âŒ è¯·æ±‚è¶…æ—¶")
            return {"error": "è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"}
        except requests.exceptions.ConnectionError:
            print("âŒ ç½‘ç»œè¿æ¥é”™è¯¯")
            return {"error": "ç½‘ç»œè¿æ¥å¤±è´¥"}
        except requests.exceptions.RequestException as e:
            print(f"âŒ ç½‘ç»œè¯·æ±‚é”™è¯¯: {str(e)}")
            return {"error": f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}"}
        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æé”™è¯¯: {str(e)}")
            return {"error": f"å“åº”è§£æå¤±è´¥: {str(e)}"}
        except Exception as e:
            print(f"âŒ æœªçŸ¥é”™è¯¯: {str(e)}")
            return {"error": f"AI APIè°ƒç”¨å¤±è´¥: {str(e)}"}

    def analyze_housing_trend(self, city: str, area: Optional[str], data: pd.DataFrame) -> Dict[str, Any]:
        """
        ä½¿ç”¨AIåˆ†ææˆ¿ä»·è¶‹åŠ¿ - ä¿®å¤ç‰ˆæœ¬
        """
        try:
            if data.empty:
                return {"error": "æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œåˆ†æ"}

            # æ•°æ®é¢„å¤„ç†å’Œç»Ÿè®¡è®¡ç®—
            data_sorted = data.sort_values('date')
            recent_data = data_sorted.tail(12)  # æœ€è¿‘12ä¸ªæœˆ

            # è®¡ç®—åŸºç¡€ç»Ÿè®¡
            current_price = float(recent_data['price'].iloc[-1]) if not recent_data.empty else None
            avg_price = float(recent_data['price'].mean()) if not recent_data.empty else None
            price_change = None
            price_change_pct = None

            if len(recent_data) >= 2:
                old_price = float(recent_data['price'].iloc[0])
                price_change = current_price - old_price
                price_change_pct = (price_change / old_price) * 100

            location = f"{city}å¸‚{area}åŒºåŸŸ" if area else f"{city}å¸‚"

            # ç®€åŒ–çš„åˆ†ææç¤ºï¼Œé¿å…è¿‡é•¿
            system_prompt = """ä½ æ˜¯ä¸“ä¸šçš„æˆ¿åœ°äº§åˆ†æå¸ˆã€‚è¯·ç”¨ä¸­æ–‡åˆ†ææˆ¿ä»·æ•°æ®ï¼Œæä¾›ç®€æ´å®ç”¨çš„åˆ†æå’Œå»ºè®®ã€‚"""

            user_prompt = f"""åˆ†æ{location}æˆ¿ä»·è¶‹åŠ¿ï¼š

å½“å‰ä»·æ ¼ï¼š{current_price:.0f}å…ƒ/ã¡
å¹³å‡ä»·æ ¼ï¼š{avg_price:.0f}å…ƒ/ã¡
ä»·æ ¼å˜åŒ–ï¼š{price_change_pct:.1f}%
æ•°æ®æœŸé—´ï¼š{len(recent_data)}ä¸ªæœˆ

è¯·æä¾›ï¼š
1. è¶‹åŠ¿åˆ¤æ–­ï¼ˆä¸Šæ¶¨/ä¸‹è·Œ/å¹³ç¨³ï¼‰
2. ä»·æ ¼æ°´å¹³è¯„ä¼°
3. æŠ•èµ„å»ºè®®ï¼ˆ3-4æ¡ï¼‰
4. é£é™©æç¤º

è¯·ç”¨ç®€æ´ä¸“ä¸šçš„è¯­è¨€å›ç­”ï¼Œé‡ç‚¹çªå‡ºã€‚"""

            print(f"ğŸ¤– å¼€å§‹AIåˆ†æ: {location}")

            # è°ƒç”¨AI API
            result = self.chat_with_ai(user_prompt, system_prompt)

            # å¤„ç†AIå“åº”
            if "error" not in result:
                # æ·»åŠ åŸºç¡€ç»Ÿè®¡æ•°æ®
                result["basic_stats"] = {
                    "current_price": round(current_price, 2) if current_price else None,
                    "average_price": round(avg_price, 2) if avg_price else None,
                    "price_change": round(price_change, 2) if price_change else None,
                    "price_change_percentage": round(price_change_pct, 2) if price_change_pct else None,
                    "sample_count": len(recent_data),
                    "price_range": {
                        "min": round(float(recent_data['price'].min()), 2),
                        "max": round(float(recent_data['price'].max()), 2)
                    }
                }
                print(f"âœ… AIåˆ†æå®Œæˆ")
            else:
                print(f"âŒ AIåˆ†æå¤±è´¥: {result['error']}")

            return result

        except Exception as e:
            print(f"âŒ æˆ¿ä»·è¶‹åŠ¿åˆ†æå‡ºé”™: {str(e)}")
            return {"error": f"åˆ†æå¤±è´¥: {str(e)}"}

# åˆ›å»ºå…¨å±€æœåŠ¡å®ä¾‹
ai_service = AIService()



# Authç›¸å…³æ¨¡å‹å’Œå‡½æ•°
from pydantic import BaseModel, EmailStr
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
import re

security = HTTPBearer(auto_error=False)

class UserRegister(BaseModel):
    username: str
    email: EmailStr
    password: str
    full_name: Optional[str] = None

class UserLogin(BaseModel):
    username: str  # å¯ä»¥æ˜¯ç”¨æˆ·åæˆ–é‚®ç®±
    password: str

class UserResponse(BaseModel):
    id: int
    username: str
    email: str
    full_name: Optional[str] = None
    created_at: str
    last_login: Optional[str] = None

class LoginResponse(BaseModel):
    message: str
    user: UserResponse
    token: str
    expires_at: str

def validate_username(username: str) -> bool:
    """éªŒè¯ç”¨æˆ·åæ ¼å¼"""
    if not username or len(username) < 3 or len(username) > 50:
        return False
    return bool(re.match(r'^[a-zA-Z0-9_]+$', username))

def validate_password(password: str) -> bool:
    """éªŒè¯å¯†ç å¼ºåº¦"""
    if not password or len(password) < 6:
        return False
    return True

def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """è·å–å½“å‰ç™»å½•ç”¨æˆ·"""
    token = credentials.credentials
    result = UserManager.verify_token(token)
    if not result.get("success"):
        raise HTTPException(status_code=401, detail="Invalid token")
    return result["user"]

# æ·»åŠ ç®¡ç†å‘˜æƒé™æ£€æŸ¥å‡½æ•°
def is_admin_user(user: dict) -> bool:
    """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦ä¸ºç®¡ç†å‘˜"""
    return user.get("full_name") == "ç®¡ç†å‘˜"

def require_admin_permission(current_user: dict = Depends(get_current_user)):
    """è¦æ±‚ç®¡ç†å‘˜æƒé™çš„ä¾èµ–é¡¹"""
    if not is_admin_user(current_user):
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="æƒé™ä¸è¶³ï¼šéœ€è¦ç®¡ç†å‘˜æƒé™"
        )
    return current_user

def get_optional_user(credentials: Optional[HTTPAuthorizationCredentials] = Depends(security)):
    if not credentials:
        return None
    try:
        return get_current_user(credentials)
    except HTTPException:
        return None


app = FastAPI(title="æˆ¿ä»·åˆ†æç³»ç»Ÿåç«¯API")

# å…è®¸è·¨åŸŸï¼Œä¾¿äºå‰ç«¯æœ¬åœ°å¼€å‘
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆå§‹åŒ–æ•°æ®åº“
@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–æ•°æ®åº“"""
    print("æ­£åœ¨åˆå§‹åŒ–SQLiteæ•°æ®åº“...")
    try:
        if init_sqlite_database():
            print("SQLiteæ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
        else:
            print("SQLiteæ•°æ®åº“åˆå§‹åŒ–å¤±è´¥")
    except Exception as e:
        print(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        print("ç³»ç»Ÿå°†ä»¥åŸºç¡€æ¨¡å¼è¿è¡Œï¼Œç”¨æˆ·ç®¡ç†åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")

# æ•°æ®åŠ è½½
DATA_PATH = os.path.join(os.path.dirname(__file__), '..', 'data', 'housing_data.csv')
df = pd.read_csv(DATA_PATH)
df['date'] = pd.to_datetime(df['date'])


@app.get("/")
def read_root():
    return {"message": "æ¬¢è¿ä½¿ç”¨æˆ¿ä»·åˆ†æç³»ç»ŸAPI"}

@app.get("/search")
def search(city: str):
    """æŒ‰åŸå¸‚åç§°æœç´¢æˆ¿ä»·æ•°æ®"""
    city_df = df[df['city'] == city]
    if city_df.empty:
        return {"city": city, "data": []}
    
    # è·å–æœ€æ–°æœˆä»½çš„æ•°æ®
    latest_date = city_df['date'].max()
    latest_df = city_df[city_df['date'] == latest_date]
    
    data = latest_df[['area', 'price']].to_dict(orient='records')
    return {"city": city, "data": data}

@app.get("/areas")
def get_areas(city: str):
    """è·å–æŒ‡å®šåŸå¸‚çš„æ‰€æœ‰åŒºåŸŸåˆ—è¡¨"""
    city_df = df[df['city'] == city]
    if city_df.empty:
        return {"city": city, "areas": []}
    
    areas = sorted(city_df['area'].unique().tolist())
    return {"city": city, "areas": areas}

@app.get("/trend")
def trend(city: str, area: str):
    """æŒ‰åŒºåŸŸåˆ†ææˆ¿ä»·èµ°åŠ¿"""
    trend_df = df[(df['city'] == city) & (df['area'] == area)].copy()
    if trend_df.empty:
        return {"city": city, "area": area, "trend": []}
        
    # æŒ‰æœˆåˆ†ç»„å¹¶è®¡ç®—å‡ä»·ï¼Œç¡®ä¿æ¯ä¸ªæœˆåªæœ‰ä¸€ä¸ªæ•°æ®ç‚¹
    trend_df['date'] = pd.to_datetime(trend_df['date'])
    trend_df['month'] = trend_df['date'].dt.to_period('M')
    monthly_avg = trend_df.groupby('month')['price'].mean().reset_index()
    
    # æ ¼å¼åŒ–æ—¥æœŸä¸º 'YYYY-MM' ä»¥ä¾¿å‰ç«¯å±•ç¤º
    monthly_avg['date'] = monthly_avg['month'].dt.strftime('%Y-%m')
    monthly_avg.sort_values('month', inplace=True)
    
    trend_data = monthly_avg[['date', 'price']].to_dict(orient='records')
    return {"city": city, "area": area, "trend": trend_data}

@app.get("/city_all_trends")
def get_city_all_trends(city: str):
    """è·å–æŒ‡å®šåŸå¸‚æ‰€æœ‰åŒºåŸŸçš„æˆ¿ä»·èµ°åŠ¿æ•°æ®"""
    try:
        city_df = df[df['city'] == city].copy()
        if city_df.empty:
            raise HTTPException(status_code=404, detail=f"æœªæ‰¾åˆ°åŸå¸‚ '{city}' çš„æ•°æ®")
        
        # è·å–è¯¥åŸå¸‚çš„æ‰€æœ‰åŒºåŸŸ
        areas = sorted(city_df['area'].unique())
        
        # ä¸ºæ¯ä¸ªåŒºåŸŸè®¡ç®—è¶‹åŠ¿æ•°æ®
        all_trends = {}
        for area in areas:
            area_df = city_df[city_df['area'] == area].copy()
            if not area_df.empty:
                # æŒ‰æœˆåˆ†ç»„å¹¶è®¡ç®—å‡ä»·
                area_df['month'] = area_df['date'].dt.to_period('M')
                monthly_avg = area_df.groupby('month')['price'].mean().reset_index()
                monthly_avg['date'] = monthly_avg['month'].dt.strftime('%Y-%m')
                monthly_avg.sort_values('month', inplace=True)
                
                trend_data = monthly_avg[['date', 'price']].to_dict(orient='records')
                all_trends[area] = trend_data
        
        return {
            "city": city,
            "areas": areas,
            "trends": all_trends
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–åŸå¸‚è¶‹åŠ¿æ•°æ®å¤±è´¥: {str(e)}")

@app.get("/compare")
def compare(city1: str, city2: str):
    """å¯¹æ¯”ä¸åŒåŸå¸‚æœ€è¿‘6ä¸ªæœˆçš„æˆ¿ä»·èµ°åŠ¿"""
    
    # è·å–æ•°æ®ä¸­æœ€è¿‘çš„æ—¥æœŸï¼Œå¹¶è®¡ç®—6ä¸ªæœˆå‰çš„æ—¥æœŸ
    latest_date = df['date'].max()
    # è·å–æœ€è¿‘6ä¸ªä¸åŒçš„æœˆä»½
    recent_months = df['date'].dt.to_period('M').unique()
    if len(recent_months) < 6:
        six_months_ago = recent_months.min().to_timestamp()
    else:
        six_months_ago = recent_months[-6].to_timestamp()


    def get_city_trend(city):
        # ç­›é€‰å‡ºå¯¹åº”åŸå¸‚å’Œæœ€è¿‘6ä¸ªæœˆçš„æ•°æ®
        city_df = df[(df['city'] == city) & (df['date'] >= six_months_ago)].copy()
        if city_df.empty:
            return []
        # æŒ‰æœˆåˆ†ç»„å¹¶è®¡ç®—å‡ä»·
        city_df['month'] = city_df['date'].dt.to_period('M')
        monthly_avg = city_df.groupby('month')['price'].mean().reset_index()
        monthly_avg['date'] = monthly_avg['month'].dt.strftime('%Y-%m')
        monthly_avg.sort_values('month', inplace=True)
        # ç¡®ä¿æˆ‘ä»¬åªè¿”å›æœ€è¿‘6ä¸ªæœˆçš„æ•°æ®
        return monthly_avg.tail(6)[['date', 'price']].to_dict(orient='records')

    trend1 = get_city_trend(city1)
    trend2 = get_city_trend(city2)

    return {
        "trend_data": {
            city1: trend1,
            city2: trend2
        }
    }

@app.get("/stats")
def get_stats(city: str):
    """è·å–æŒ‡å®šåŸå¸‚çš„æœ€æ–°æˆ¿ä»·ç»Ÿè®¡æ•°æ®"""
    try:
        city_df = df[df['city'] == city]
        if city_df.empty:
            raise HTTPException(status_code=404, detail=f"æœªæ‰¾åˆ°åŸå¸‚ '{city}' çš„æ•°æ®")

        # è·å–æœ€æ–°æœˆä»½çš„æ•°æ®
        latest_date = city_df['date'].max()
        latest_df = city_df[city_df['date'] == latest_date]

        if latest_df.empty or latest_df['price'].count() < 2:
            return {"city": city, "stats": {}, "message": f"'{city}' çš„æœ€æ–°æ•°æ®ä¸è¶³(å°‘äº2ä¸ª)ï¼Œæ— æ³•è¿›è¡Œæœ‰æ•ˆçš„ç»Ÿè®¡åˆ†æ"}

        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        stats_raw = latest_df['price'].describe()
        stats = stats_raw.to_dict()
        
        # å°† numpy ç±»å‹è½¬æ¢ä¸º python åŸç”Ÿç±»å‹ï¼Œç¡®ä¿JSONå…¼å®¹æ€§
        for key, value in stats.items():
            if isinstance(value, np.integer):
                stats[key] = int(value)
            elif isinstance(value, np.floating):
                stats[key] = round(float(value), 2) # ä¿ç•™ä¸¤ä½å°æ•°

        # æ·»åŠ ä¸€äº›è‡ªå®šä¹‰çš„ã€æ›´æ˜“è¯»çš„ç»Ÿè®¡é¡¹
        stats['range'] = stats['max'] - stats['min'] # æå·®
        stats['variance'] = round(latest_df['price'].var(), 2) # æ–¹å·®
        stats['coefficient_of_variation'] = round(stats['std'] / stats['mean'], 2) if stats['mean'] > 0 else 0 # å˜å¼‚ç³»æ•°

        return {"city": city, "stats": stats}
    except Exception as e:
        # é€šç”¨é”™è¯¯å¤„ç†
        raise HTTPException(status_code=500, detail=f"å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯: {str(e)}")

# Pydantic æ¨¡å‹
class AIQueryRequest(BaseModel):
    query: str
    city: Optional[str] = None
    area: Optional[str] = None



# ==================== ç”¨æˆ·ç®¡ç†APIæ¥å£ ====================

@app.post("/auth/register", response_model=dict)
def register_user(user_data: UserRegister):
    """ç”¨æˆ·æ³¨å†Œ"""
    try:
        # éªŒè¯ç”¨æˆ·åæ ¼å¼
        if not validate_username(user_data.username):
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="ç”¨æˆ·åæ ¼å¼ä¸æ­£ç¡®ï¼Œé•¿åº¦3-20ä½ï¼Œåªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿"
            )
        
        # éªŒè¯å¯†ç å¼ºåº¦
        if not validate_password(user_data.password):
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="å¯†ç é•¿åº¦è‡³å°‘6ä½"
            )
        
        result = UserManager.create_user(
            username=user_data.username,
            email=user_data.email,
            password=user_data.password,
            full_name=user_data.full_name
        )
        
        if result["success"]:
            return {
                "success": True,
                "message": result["message"],
                "user": result["user"]
            }
        else:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=result["message"]
            )
            
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æ³¨å†Œå¤±è´¥: {str(e)}"
        )

@app.post("/auth/login")
def login_user(login_data: UserLogin):
    """ç”¨æˆ·ç™»å½•"""
    try:
        result = UserManager.authenticate_user(
            username=login_data.username,
            password=login_data.password
        )
        
        if result["success"]:
            # è®°å½•ç™»å½•æ´»åŠ¨
            log_user_activity(
                user_id=result["user"]["id"],
                activity_type="login",
                activity_data={"ip": "127.0.0.1"}  # åœ¨å®é™…éƒ¨ç½²ä¸­å¯ä»¥è·å–çœŸå®IP
            )
            
            return {
                "success": True,
                "message": result["message"],
                "user": result["user"],
                "token": result["token"],
                "expires_at": result["expires_at"]
            }
        else:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail=result["message"]
            )
            
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ç™»å½•å¤±è´¥: {str(e)}"
        )

@app.post("/auth/logout")
def logout_user(current_user: dict = Depends(get_current_user)):
    """ç”¨æˆ·ç™»å‡º"""
    try:
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ä»è¯·æ±‚å¤´è·å–tokenï¼Œå®é™…å®ç°å¯èƒ½éœ€è¦è°ƒæ•´
        # ä¸ºç®€åŒ–ï¼Œæˆ‘ä»¬è®°å½•ç™»å‡ºæ´»åŠ¨
        log_user_activity(
            user_id=current_user["id"],
            activity_type="logout"
        )
        
        return {"success": True, "message": "ç™»å‡ºæˆåŠŸ"}
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ç™»å‡ºå¤±è´¥: {str(e)}"
        )

@app.get("/auth/me")
def get_current_user_info(current_user: dict = Depends(get_current_user)):
    """è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯"""
    # æ·»åŠ ç®¡ç†å‘˜èº«ä»½æ ‡è¯†
    user_info = current_user.copy()
    user_info["is_admin"] = is_admin_user(current_user)
    
    return {
        "success": True,
        "user": user_info
    }

@app.get("/auth/users")
def get_all_users(current_user: dict = Depends(require_admin_permission)):
    """è·å–æ‰€æœ‰ç”¨æˆ·åˆ—è¡¨ï¼ˆç®¡ç†å‘˜åŠŸèƒ½ï¼‰"""
    try:
        result = UserManager.get_user_list()
        
        if result["success"]:
            # è®°å½•æŸ¥çœ‹ç”¨æˆ·åˆ—è¡¨æ´»åŠ¨
            log_user_activity(
                user_id=current_user["id"],
                activity_type="view_users"
            )
            
            return {
                "success": True,
                "users": result["users"]
            }
        else:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=result["message"]
            )
            
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–ç”¨æˆ·åˆ—è¡¨å¤±è´¥: {str(e)}"
        )

# ==================== éœ€è¦ç™»å½•çš„æˆ¿ä»·åˆ†ææ¥å£ ====================

@app.get("/protected/search")
def protected_search(city: str, current_user: dict = Depends(get_current_user)):
    """éœ€è¦ç™»å½•çš„æˆ¿ä»·æœç´¢ï¼ˆç¤ºä¾‹ï¼‰"""
    # è®°å½•ç”¨æˆ·æ´»åŠ¨
    log_user_activity(
        user_id=current_user["id"],
        activity_type="search",
        activity_data={"city": city}
    )
    
    # è°ƒç”¨åŸæœ‰çš„æœç´¢åŠŸèƒ½
    return search(city)

@app.get("/protected/trend")
def protected_trend(city: str, area: str, current_user: dict = Depends(get_current_user)):
    """éœ€è¦ç™»å½•çš„è¶‹åŠ¿åˆ†æï¼ˆç¤ºä¾‹ï¼‰"""
    # è®°å½•ç”¨æˆ·æ´»åŠ¨
    log_user_activity(
        user_id=current_user["id"],
        activity_type="trend_analysis",
        activity_data={"city": city, "area": area}
    )
    
    # è°ƒç”¨åŸæœ‰çš„è¶‹åŠ¿åˆ†æåŠŸèƒ½
    return trend(city, area)

# åˆ›å»ºé¢„æµ‹ç›¸å…³çš„è·¯ç”±
prediction_router = APIRouter()

# é¢„æµ‹è¯·æ±‚æ¨¡å‹
class PredictionRequest(BaseModel):
    city: str
    area: str
    model_type: str = "DNN"  # DNN, LSTM, Prophet
    periods: int = 6  # é¢„æµ‹æœªæ¥å‡ ä¸ªæœˆ
    features: List[str] = ["month", "year", "price"]

# é¢„æµ‹ç»“æœæ¨¡å‹
class PredictionResponse(BaseModel):
    success: bool
    message: Optional[str] = None
    predictions: Optional[List[dict]] = None
    metrics: Optional[dict] = None

# åŠ è½½æˆ¿ä»·æ•°æ®
def load_housing_data():
    csv_path = os.path.join("data", "housing_data.csv")
    if not os.path.exists(csv_path):
        raise FileNotFoundError(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")

    return pd.read_csv(csv_path)

# è·å–é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
def get_model_path(city: str, area: str, model_type: str):
    model_dir = os.path.join("models", city, area)
    os.makedirs(model_dir, exist_ok=True)

    filename = f"{model_type.lower()}_model.pkl"
    return os.path.join(model_dir, filename)

# è®­ç»ƒå¹¶è·å–æ¨¡å‹
def get_or_train_model(city: str, area: str, model_type: str, df: pd.DataFrame):
    model_path = get_model_path(city, area, model_type)

    # å¦‚æœæ¨¡å‹å·²å­˜åœ¨å¹¶ä¸”ä¸è¶…è¿‡7å¤©ï¼Œåˆ™ç›´æ¥åŠ è½½
    if os.path.exists(model_path):
        model_time = os.path.getmtime(model_path)
        if (datetime.now() - datetime.fromtimestamp(model_time)).days < 7:
            return joblib.load(model_path)

    # å¦åˆ™é‡æ–°è®­ç»ƒæ¨¡å‹
    if model_type == "DNN":
        model = train_dnn_model(df)
    elif model_type == "LSTM":
        model = train_lstm_model(df)
    elif model_type == "Prophet":
        model = train_prophet_model(df)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")

    # ä¿å­˜æ¨¡å‹
    joblib.dump(model, model_path)
    return model

# DNNæ¨¡å‹è®­ç»ƒå‡½æ•°
def train_dnn_model(df):
    # ç®€åŒ–ç‰ˆå®ç°ï¼Œå®é™…é¡¹ç›®ä¸­éœ€è¦æ›´å¤æ‚çš„æ¨¡å‹
    from sklearn.preprocessing import MinMaxScaler
    from sklearn.model_selection import train_test_split
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import Dense, Dropout

    # ç‰¹å¾å·¥ç¨‹
    df['month'] = pd.to_datetime(df['date']).dt.month
    df['year'] = pd.to_datetime(df['date']).dt.year

    # å‡†å¤‡æ•°æ®
    X = df[['month', 'year']].values
    y = df['price'].values

    # å½’ä¸€åŒ–
    X_scaler = MinMaxScaler()
    y_scaler = MinMaxScaler()

    X_scaled = X_scaler.fit_transform(X)
    y_scaled = y_scaler.fit_transform(y.reshape(-1, 1))

    # æ¨¡å‹å®šä¹‰
    model = Sequential([
        Dense(64, activation='relu', input_shape=(X.shape[1],)),
        Dropout(0.2),
        Dense(32, activation='relu'),
        Dropout(0.2),
        Dense(1)
    ])

    model.compile(optimizer='adam', loss='mse')
    model.fit(X_scaled, y_scaled, epochs=100, verbose=0)

    return {
        'model': model,
        'X_scaler': X_scaler,
        'y_scaler': y_scaler
    }

# LSTMæ¨¡å‹è®­ç»ƒå‡½æ•°
def train_lstm_model(df):
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import LSTM, Dense, Dropout
    from sklearn.preprocessing import MinMaxScaler
    import numpy as np

    # å‡†å¤‡æ•°æ®
    df = df.sort_values('date')
    prices = df['price'].values.reshape(-1, 1)

    # å½’ä¸€åŒ–
    scaler = MinMaxScaler()
    prices_scaled = scaler.fit_transform(prices)

    # åˆ›å»ºåºåˆ—æ•°æ®
    lookback = 6
    X, y = [], []

    for i in range(len(prices_scaled) - lookback):
        X.append(prices_scaled[i:i+lookback])
        y.append(prices_scaled[i+lookback])

    X = np.array(X)
    y = np.array(y)

    # æ¨¡å‹å®šä¹‰
    model = Sequential([
        LSTM(50, return_sequences=True, input_shape=(lookback, 1)),
        Dropout(0.2),
        LSTM(50),
        Dropout(0.2),
        Dense(1)
    ])

    model.compile(optimizer='adam', loss='mse')
    model.fit(X, y, epochs=100, verbose=0)

    return {
        'model': model,
        'scaler': scaler,
        'lookback': lookback
    }

# Prophetæ¨¡å‹è®­ç»ƒå‡½æ•°
def train_prophet_model(df):
    from prophet import Prophet

    # å‡†å¤‡æ•°æ®
    prophet_df = df[['date', 'price']].rename(columns={'date': 'ds', 'price': 'y'})

    # è®­ç»ƒæ¨¡å‹
    model = Prophet()
    model.fit(prophet_df)

    return model

# é¢„æµ‹æ¥å£
@prediction_router.post("/predict", response_model=PredictionResponse)
async def predict_prices(request: PredictionRequest):
    try:
        # ä»CSVåŠ è½½æ•°æ®
        try:
            all_data = load_housing_data()
        except FileNotFoundError as e:
            return {"success": False, "message": str(e)}

        # ç­›é€‰æŒ‡å®šåŸå¸‚å’ŒåŒºåŸŸçš„æ•°æ®
        df = all_data[(all_data['city'] == request.city) & (all_data['area'] == request.area)]

        if df.empty:
            return {"success": False, "message": f"æ²¡æœ‰æ‰¾åˆ°{request.city}{request.area}çš„å†å²æ•°æ®"}

        # ç¡®ä¿æ—¥æœŸåˆ—ä¸ºæ—¥æœŸç±»å‹
        df['date'] = pd.to_datetime(df['date'])

        # è·å–æˆ–è®­ç»ƒæ¨¡å‹
        model_data = get_or_train_model(request.city, request.area, request.model_type, df)

        # ç”Ÿæˆé¢„æµ‹
        last_date = df['date'].max()
        future_dates = pd.date_range(start=last_date + pd.Timedelta(days=30), periods=request.periods, freq='M')

        if request.model_type == "DNN":
            predictions = predict_with_dnn(model_data, future_dates)
        elif request.model_type == "LSTM":
            predictions = predict_with_lstm(model_data, df, future_dates)
        elif request.model_type == "Prophet":
            predictions = predict_with_prophet(model_data, future_dates)
        else:
            return {"success": False, "message": f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {request.model_type}"}

        # è¯„ä¼°æŒ‡æ ‡
        metrics = calculate_metrics(df)

        return {
            "success": True,
            "predictions": predictions,
            "metrics": metrics
        }

    except Exception as e:
        return {"success": False, "message": f"é¢„æµ‹å¤±è´¥: {str(e)}"}

# DNNé¢„æµ‹å‡½æ•°
def predict_with_dnn(model_data, future_dates):
    model = model_data['model']
    X_scaler = model_data['X_scaler']
    y_scaler = model_data['y_scaler']

    # å‡†å¤‡æœªæ¥æ•°æ®
    future_features = []
    for date in future_dates:
        month = date.month
        year = date.year
        future_features.append([month, year])

    future_features = np.array(future_features)
    future_features_scaled = X_scaler.transform(future_features)

    # é¢„æµ‹
    future_pred_scaled = model.predict(future_features_scaled)
    future_pred = y_scaler.inverse_transform(future_pred_scaled)

    # è¿”å›ç»“æœ
    predictions = []
    for i, date in enumerate(future_dates):
        predictions.append({
            "date": date.strftime("%Y-%m-%d"),
            "predicted_price": float(future_pred[i][0])
        })

    return predictions

# LSTMé¢„æµ‹å‡½æ•°
def predict_with_lstm(model_data, df, future_dates):
    model = model_data['model']
    scaler = model_data['scaler']
    lookback = model_data['lookback']

    # å‡†å¤‡æœ€åä¸€ä¸ªåºåˆ—
    prices = df['price'].values.reshape(-1, 1)
    prices_scaled = scaler.transform(prices)
    last_sequence = prices_scaled[-lookback:].reshape(1, lookback, 1)

    # é¢„æµ‹æœªæ¥
    predictions = []
    current_sequence = last_sequence

    for date in future_dates:
        next_pred = model.predict(current_sequence)[0][0]
        next_pred_original = scaler.inverse_transform([[next_pred]])[0][0]

        predictions.append({
            "date": date.strftime("%Y-%m-%d"),
            "predicted_price": float(next_pred_original)
        })

        # æ›´æ–°åºåˆ—
        current_sequence = np.append(current_sequence[0, 1:, 0], next_pred)
        current_sequence = current_sequence.reshape(1, lookback, 1)

    return predictions

# Propheté¢„æµ‹å‡½æ•°
def predict_with_prophet(model, future_dates):
    # åˆ›å»ºæœªæ¥æ•°æ®æ¡†
    future_df = pd.DataFrame({"ds": future_dates})

    # é¢„æµ‹
    forecast = model.predict(future_df)

    # è¿”å›ç»“æœ
    predictions = []
    for _, row in forecast.iterrows():
        predictions.append({
            "date": row['ds'].strftime("%Y-%m-%d"),
            "predicted_price": float(row['yhat'])
        })

    return predictions

# è®¡ç®—è¯„ä¼°æŒ‡æ ‡
def calculate_metrics(df):
    # ç®€å•è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    return {
        "data_points": len(df),
        "mean_price": float(df['price'].mean()),
        "min_price": float(df['price'].min()),
        "max_price": float(df['price'].max()),
        "std_price": float(df['price'].std())
    }

# å°†è·¯ç”±æ·»åŠ åˆ°ä¸»åº”ç”¨
app.include_router(prediction_router, tags=["prediction"])

class AIChatRequest(BaseModel):
    query: str
    city: Optional[str] = None
    area: Optional[str] = None
    # å¯æ‹“å±•æ›´å¤šä¸Šä¸‹æ–‡å­—æ®µ

@app.post("/ai/assistant")
def ai_assistant(
    req: AIChatRequest,
    current_user: Optional[dict] = Depends(get_optional_user)
):
    """
    AIåŠ©æ‰‹ - æ”¯æŒé€šç”¨å¯¹è¯å’Œæˆ¿ä»·æ™ºèƒ½åˆ†æ
    """
    # è®°å½•ç”¨æˆ·èº«ä»½ï¼ˆå¯é€‰ï¼‰
    user_id = current_user["id"] if current_user else None

    # å¦‚æœæä¾›åŸå¸‚/åŒºåŸŸï¼Œå°è¯•è¶‹åŠ¿åˆ†æï¼Œå¦åˆ™ä¸ºé€šç”¨å¯¹è¯
    if req.city:
        # æ•°æ®ç­›é€‰
        area_df = df[(df['city'] == req.city)]
        if req.area:
            area_df = area_df[area_df['area'] == req.area]
        if area_df.empty:
            return {"error": f"æœªæ‰¾åˆ°{req.city}{req.area or ''}çš„æˆ¿ä»·æ•°æ®"}
        result = ai_service.analyze_housing_trend(req.city, req.area, area_df)
        return result
    else:
        # é€šç”¨AIå¯¹è¯
        ai_result = ai_service.chat_with_ai(prompt=req.query, system_prompt="ä½ æ˜¯ä¸“ä¸šçš„æˆ¿åœ°äº§æ™ºèƒ½åŠ©æ‰‹ï¼Œè¯·ç”¨ä¸­æ–‡ç®€æ˜å›ç­”ç”¨æˆ·é—®é¢˜ã€‚")
        return ai_result
@app.get("/cities")
def get_cities():
    """è·å–æ‰€æœ‰åŸå¸‚åˆ—è¡¨"""
    cities = sorted(df['city'].unique().tolist())
    return {"cities": cities}

